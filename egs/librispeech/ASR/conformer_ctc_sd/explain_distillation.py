#!/usr/bin/env python3
"""
Simple explanation of attention map sizes and encoder outputs
"""

import torch
from conformer_ctc import ConformerCTC

def explain_attention_map_sizes():
    """Explain how attention map sizes are determined"""
    print("ğŸ” ATTENTION MAP SIZE EXPLANATION")
    print("=" * 50)
    
    print("Attention Map SizeëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê²°ì •ë©ë‹ˆë‹¤:")
    print()
    print("1. ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´:")
    print("   - ì›ë³¸ ì˜¤ë””ì˜¤ í”„ë ˆì„ ìˆ˜ì— ë”°ë¼ ê²°ì •")
    print("   - ì˜ˆ: 100 í”„ë ˆì„ -> 100 ê¸¸ì´")
    print()
    print("2. Subsampling íš¨ê³¼:")
    print("   - ConformerëŠ” ì´ˆê¸° ë ˆì´ì–´ì—ì„œ subsampling ìˆ˜í–‰")
    print("   - ë³´í†µ 4ë°° ë˜ëŠ” 6ë°° ì••ì¶•")
    print("   - ì˜ˆ: 100 -> 25 (4ë°°), 100 -> 16 (6ë°°)")
    print()
    print("3. Attention Map í˜•íƒœ:")
    print("   - [batch_size, num_heads, seq_len, seq_len]")
    print("   - seq_lenì€ í•´ë‹¹ ë ˆì´ì–´ì—ì„œì˜ ì‹œí€€ìŠ¤ ê¸¸ì´")
    print("   - subsampling í›„ì—ëŠ” ëª¨ë“  ë ˆì´ì–´ê°€ ê°™ì€ seq_len")
    print()
    
    # Create test model
    model = ConformerCTC(
        num_features=80,
        num_classes=500,
        d_model=256,
        num_encoder_layers=6,
        nhead=4,
        distill_layers=[2, 4],
        knowledge_type='attention-map',
    )
    
    # Test with different input sizes
    test_cases = [
        {"seq_len": 50, "name": "Short audio"},
        {"seq_len": 100, "name": "Medium audio"},
        {"seq_len": 200, "name": "Long audio"}
    ]
    
    print("ì‹¤ì œ í…ŒìŠ¤íŠ¸:")
    for case in test_cases:
        seq_len = case["seq_len"]
        batch_size = 2
        
        x = torch.randn(batch_size, seq_len, 80)
        supervisions = {
            'sequence_idx': torch.arange(batch_size),
            'start_frame': torch.zeros(batch_size),
            'num_frames': torch.tensor([seq_len, seq_len]),
        }
        
        with torch.no_grad():
            outputs = model(x, supervisions)
        
        print(f"\n{case['name']} (ì…ë ¥ ê¸¸ì´: {seq_len}):")
        if 'distill_outputs' in outputs and len(outputs['distill_outputs']) > 0:
            for i, attn_map in enumerate(outputs['distill_outputs']):
                layer_idx = model.distill_layers[i]
                attn_seq_len = attn_map.shape[-1]
                compression_ratio = seq_len / attn_seq_len
                print(f"  Layer {layer_idx}: {attn_map.shape} (ì••ì¶•ë¹„: {compression_ratio:.1f}x)")

def explain_encoder_outputs():
    """Explain encoder output structure"""
    print("\nğŸ” ENCODER OUTPUT vs DISTILL OUTPUT")
    print("=" * 50)
    
    print("Encoder-Output ëª¨ë“œì—ì„œ:")
    print()
    print("1. distill_outputs:")
    print("   - ì„ íƒëœ ë ˆì´ì–´ë“¤ì˜ ì‹¤ì œ hidden states")
    print("   - ê° ë ˆì´ì–´ì˜ ì¸ì½”ë” ì¶œë ¥ (feature representations)")
    print("   - í˜•íƒœ: [batch_size, seq_len, d_model]")
    print("   - Self-distillationì— ì§ì ‘ ì‚¬ìš©ë˜ëŠ” ì •ë³´")
    print()
    print("2. distill_hidden:")
    print("   - í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” distill_outputsì™€ ë™ì¼")
    print("   - í–¥í›„ í™•ì¥ì„ ìœ„í•œ placeholder")
    print("   - ì¶”ê°€ì ì¸ ì»¨í…ìŠ¤íŠ¸ë‚˜ ì²˜ë¦¬ëœ ì •ë³´ë¥¼ ë‹´ì„ ìˆ˜ ìˆìŒ")
    print()
    
    # Test encoder output mode
    model = ConformerCTC(
        num_features=80,
        num_classes=500,
        d_model=256,
        num_encoder_layers=6,
        nhead=4,
        distill_layers=[1, 3, 5],
        knowledge_type='encoder-output',
    )
    
    batch_size = 2
    seq_len = 100
    x = torch.randn(batch_size, seq_len, 80)
    supervisions = {
        'sequence_idx': torch.arange(batch_size),
        'start_frame': torch.zeros(batch_size),
        'num_frames': torch.tensor([seq_len, seq_len]),
    }
    
    with torch.no_grad():
        outputs = model(x, supervisions)
    
    print("ì‹¤ì œ ì˜ˆì‹œ:")
    print(f"ì…ë ¥ í¬ê¸°: {x.shape}")
    print(f"ì„ íƒëœ ë ˆì´ì–´: {model.distill_layers}")
    print()
    
    if 'distill_outputs' in outputs:
        print("distill_outputs (ê° ë ˆì´ì–´ì˜ hidden states):")
        for i, enc_out in enumerate(outputs['distill_outputs']):
            layer_idx = model.distill_layers[i]
            print(f"  Layer {layer_idx}: {enc_out.shape}")
    
    print()
    print("ğŸ“ ìš”ì•½:")
    print("- Attention Map: ì‹œí€€ìŠ¤ ê¸¸ì´ëŠ” subsamplingì— ì˜í•´ ê²°ì •")
    print("- Encoder Output: ê° ë ˆì´ì–´ì˜ feature representation")
    print("- distill_outputsê°€ self-distillationì˜ í•µì‹¬ ë°ì´í„°")

if __name__ == "__main__":
    try:
        explain_attention_map_sizes()
        explain_encoder_outputs()
        print("\nâœ… ì„¤ëª… ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
